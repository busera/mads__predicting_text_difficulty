{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v1.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this notebook is to:\n",
    "- systematically removing individual features or components from the base models to understand their impact on the model's overall performance\n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "WYr9Yqm_R0l7",
    "outputId": "140b5e6d-25b2-442b-fcf7-9ad7b542248c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a Goolge Drive Environment.\n"
     ]
    }
   ],
   "source": [
    "## Check for Google Drive Connectivity\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    google_env = True\n",
    "except:\n",
    "    print(\"Not a Goolge Drive Environment.\")\n",
    "    google_env = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "T_FulwOgR0l8"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "t_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "RxZajmxMR0l9",
    "outputId": "4c3865f2-f919-4810-8721-9cf23dca833a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "Fastrun enabled: False\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Use parameters to enable/disable the fastrun\n",
    "\n",
    "FASTRUN = False\n",
    "#FASTRUN = True\n",
    "\n",
    "# Size of the fastrun dataframe\n",
    "sample_fraction = 0.001\n",
    "print(\"===\"*40)\n",
    "print(\"Fastrun enabled:\", FASTRUN)\n",
    "if FASTRUN: print(\"Sample size:\",sample_fraction)\n",
    "print(\"===\"*40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZms1pauBzw0"
   },
   "source": [
    "# Setup Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSazCCmDbqKg"
   },
   "source": [
    "## Install Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "1Vo8zBrWbqKg"
   },
   "outputs": [],
   "source": [
    "#!pip install watermark\n",
    "#!pip install icecream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHwYAoFSBzw1"
   },
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "nbk1jSYhBzw2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n"
     ]
    }
   ],
   "source": [
    "# Base libraries\n",
    "import os\n",
    "from datetime import date\n",
    "\n",
    "# Scientific libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (12,8)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(12,8)})\n",
    "sns.set(font_scale=0.8)\n",
    "\n",
    "# Helper libraries\n",
    "from watermark import watermark\n",
    "from icecream import ic\n",
    "import gc # garbage collection to optimize memory usage: use \"gc.collect()\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Pandas options\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "# Load magic commands\n",
    "%load_ext watermark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "C46IJ3IeBzw5"
   },
   "source": [
    "## Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "rVPFKtMUBzw6"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "cpu_count = os.cpu_count()\n",
    "cpu_count = cpu_count-2  # to keep machine responsive when fitting the models\n",
    "notebook_no = \"04.04\"\n",
    "today = date.today()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "SdUPJZbDR0mA"
   },
   "source": [
    "## Global Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "EdpbueLMR0mA"
   },
   "outputs": [],
   "source": [
    "import http.client\n",
    "import urllib\n",
    "\n",
    "\n",
    "def send_push(message):\n",
    "    \"\"\"Send push notifications to pushover service.\"\"\"\n",
    "    try:\n",
    "        conn = http.client.HTTPSConnection(\"api.pushover.net:443\")\n",
    "        conn.request(\"POST\", \"/1/messages.json\",\n",
    "                     urllib.parse.urlencode({\n",
    "                         \"token\": \"ahs1q4mwpnxe3645zeaqzas69whq7a\",  # ML Notifications Channel\n",
    "                         \"user\": \"u5vr1qkc9ghudg2ehuug153okeiz1d\",\n",
    "                         \"message\": message,\n",
    "                     }), {\"Content-type\": \"application/x-www-form-urlencoded\"})\n",
    "\n",
    "        conn.getresponse()\n",
    "\n",
    "    except:\n",
    "        print(\"There was a communication issue (pushover).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "fYeTVfQeR0mA"
   },
   "outputs": [],
   "source": [
    "def fast_run_sampling(df, sample_fraction):\n",
    "    \"\"\"Return a fraction of the dataset.\"\"\"\n",
    "    print(\"Labels before sampling:\\n\", df['label'].value_counts())\n",
    "    df = df.groupby('label').sample(frac=sample_fraction, random_state=seed) \n",
    "    #df = df.sample(n=sample_size, random_state=seed).reset_index(drop=True)\n",
    "    print(\"Labels after sampling:\\n\", df['label'].value_counts())\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_duration(t_start, t_end):\n",
    "    \"\"\"Return run time in minutes.\"\"\"\n",
    "    total_runtime = t_end-t_start\n",
    "    total_runtime_min = round((total_runtime/60), 2)\n",
    "    print(str(total_runtime_min)+\" minutes\")\n",
    "\n",
    "    return total_runtime_min\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6YBbHzbqBzw8"
   },
   "source": [
    "# 3.0 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "QUyCYBdWdeWq",
    "outputId": "a05ad7b5-365e-4110-d00f-ab95996998b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a Google Drive Environment. Loading local files.\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "if google_env:\n",
    "    # Location for \"shared with\" people\n",
    "    # create a shortcut of the shared folder in your Google Drive root folder\n",
    "    ROOT_PATH = \"/content/drive/MyDrive/SIADS696/Environment/\"\n",
    "else:\n",
    "    ROOT_PATH = \"../\"\n",
    "    print(\"Not a Google Drive Environment. Loading local files.\")\n",
    "\n",
    "PATH_DATA = \"data/\"\n",
    "PATH_DATA_RAW = \"data/raw/\"\n",
    "PATH_DATA_INT = \"data/interim/\"\n",
    "PATH_DATA_PRO = \"data/processed/\"\n",
    "PATH_DATA_MOD = \"models/\"\n",
    "PATH_DATA_REP = \"reports/\"\n",
    "PATH_DATA_FIG = \"reports/figures/\"\n",
    "PATH_DATA_HTML = \"reports/html/\"\n",
    "\n",
    "df_wiki_train_stats = pd.read_parquet(ROOT_PATH + PATH_DATA_INT + \"train_features_clean_stats.parquet.gzip\")\n",
    "df_wiki_train_rs = pd.read_parquet(ROOT_PATH + PATH_DATA_INT+\"train_features_rs.parquet.gzip\")\n",
    "df_wiki_train_nltk = pd.read_parquet(ROOT_PATH + PATH_DATA_INT+\"train_features_nltk.parquet.gzip\")\n",
    "df_wiki_train_aoa = pd.read_parquet(ROOT_PATH + PATH_DATA_INT+\"train_features_aoa.parquet.gzip\")\n",
    "df_wiki_train_crb = pd.read_parquet(ROOT_PATH + PATH_DATA_INT+\"train_features_crb.parquet.gzip\")\n",
    "df_wiki_train_w2v = pd.read_parquet(ROOT_PATH + PATH_DATA_INT+\"train_features_w2v.parquet.gzip\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "e2HJrw_6R0mE"
   },
   "source": [
    "# Feature Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model selection\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Scaling and pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Linear models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Linear/Stochastic Gradient Descent\n",
    "from sklearn.linear_model import SGDClassifier \n",
    "\n",
    "# Tree models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# NB models\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Neighbors models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Ensemble models\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = {\n",
    "    'Random Forerst': RandomForestClassifier(random_state=seed, n_jobs=cpu_count),\n",
    "    # 'Extra Trees': ExtraTreesClassifier(),\n",
    "    # 'XGBoost': XGBClassifier(),\n",
    "    # 'CatBoost': CatBoostClassifier(logging_level='Silent', random_seed=seed),\n",
    "    # 'Logistic Regression': LogisticRegression(random_state=seed, n_jobs=cpu_count, max_iter=1000),\n",
    "    # 'Gaussian NB': GaussianNB(),\n",
    "    # 'Multinomial NB': MultinomialNB(),\n",
    "    # 'Decision Tree': DecisionTreeClassifier(),\n",
    "    # 'KNeighbors': KNeighborsClassifier(),\n",
    "    # 'SGDC': SGDClassifier(),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_acc(model_pipeline, X, y):\n",
    "    gc.collect()\n",
    "    acc_list = []\n",
    "    scoring_list = ['accuracy']\n",
    "\n",
    "    for name, model in model_pipeline.items():\n",
    "        gc.collect()\n",
    "        print(\"Cross-validating:\", name)\n",
    "\n",
    "        pipeline = Pipeline([('scaling', scaler), ('estimator', model)])\n",
    "        cv_results = cross_validate(pipeline, X, y, cv=skfold, scoring=scoring_list, \n",
    "                                    return_estimator =True, error_score='raise', n_jobs=-1)\n",
    "\n",
    "        acc_list.append(np.mean(cv_results['test_accuracy']))\n",
    "        print(np.mean(cv_results['test_accuracy']));\n",
    "        \n",
    "        if not FASTRUN:\n",
    "            message = (\n",
    "                f\"Cross-validation accuracy score base model {name}:\", (np.mean(cv_results['test_accuracy'])))\n",
    "            send_push(message)\n",
    "\n",
    "        return np.mean(cv_results['test_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "skfold = StratifiedKFold(n_splits=k)\n",
    "rf = RandomForestClassifier(random_state=seed, n_jobs=-1)\n",
    "scaler = MinMaxScaler((0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list = []\n",
    "features_list = []\n",
    "dataframes_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df_list = [\n",
    "    df_wiki_train_stats,\n",
    "    df_wiki_train_rs,\n",
    "    df_wiki_train_nltk,\n",
    "    df_wiki_train_aoa,\n",
    "    df_wiki_train_crb,\n",
    "    df_wiki_train_w2v,\n",
    "]\n",
    "\n",
    "dataset_list = [\n",
    "    \"df_wiki_train_stats\",\n",
    "    \"df_wiki_train_rs\",\n",
    "    \"df_wiki_train_nltk\",\n",
    "    \"df_wiki_train_aoa\",\n",
    "    \"df_wiki_train_crb\",\n",
    "    \"df_wiki_train_w2v\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(416768, 155)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.concat(dataset_df_list, axis=1)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(416768, 151)\n",
      "(416768,)\n"
     ]
    }
   ],
   "source": [
    "X_columns_train = df_train.columns.to_list()\n",
    "X_columns_train = list(set(X_columns_train) - {\"label\", \"original_text\", \"cleaned_text\", \"stats_language_code\"})\n",
    "\n",
    "X = df_train[X_columns_train].copy()\n",
    "y = df_wiki_train_stats[\"label\"]\n",
    "\n",
    "print(X.shape);\n",
    "print(y.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validating: Random Forerst\n",
      "0.7488890715367489\n"
     ]
    }
   ],
   "source": [
    "result = calculate_acc(model_pipeline, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_list.append(dataset_list)\n",
    "features_list.append(len(X_columns_train))\n",
    "acc_list.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| list_of_dataset_list: [['df_wiki_train_rs',\n",
      "                            'df_wiki_train_nltk',\n",
      "                            'df_wiki_train_aoa',\n",
      "                            'df_wiki_train_crb',\n",
      "                            'df_wiki_train_w2v'],\n",
      "                           ['df_wiki_train_stats',\n",
      "                            'df_wiki_train_nltk',\n",
      "                            'df_wiki_train_aoa',\n",
      "                            'df_wiki_train_crb',\n",
      "                            'df_wiki_train_w2v'],\n",
      "                           ['df_wiki_train_stats',\n",
      "                            'df_wiki_train_rs',\n",
      "                            'df_wiki_train_aoa',\n",
      "                            'df_wiki_train_crb',\n",
      "                            'df_wiki_train_w2v'],\n",
      "                           ['df_wiki_train_stats',\n",
      "                            'df_wiki_train_rs',\n",
      "                            'df_wiki_train_nltk',\n",
      "                            'df_wiki_train_crb',\n",
      "                            'df_wiki_train_w2v'],\n",
      "                           ['df_wiki_train_stats',\n",
      "                            'df_wiki_train_rs',\n",
      "                            'df_wiki_train_nltk',\n",
      "                            'df_wiki_train_aoa',\n",
      "                            'df_wiki_train_w2v'],\n",
      "                           ['df_wiki_train_stats',\n",
      "                            'df_wiki_train_rs',\n",
      "                            'df_wiki_train_nltk',\n",
      "                            'df_wiki_train_aoa',\n",
      "                            'df_wiki_train_crb']]\n"
     ]
    }
   ],
   "source": [
    "# Loop through the list and exclude one and create a list; this is used to visualize the selected dataframes later\n",
    "# I was not able to realize this with a dictionary, therefore two different lists are used\n",
    "\n",
    "concatenated_df = pd.DataFrame()\n",
    "list_of_dataset_list = []\n",
    "for i, dataset in enumerate(dataset_list):  \n",
    "    # Exclude the i-th dataset\n",
    "    excluded_dataset_list = dataset_list[:i] + dataset_list[i+1:]\n",
    "    list_of_dataset_list.append(excluded_dataset_list)\n",
    "ic(list_of_dataset_list);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['df_wiki_train_rs', 'df_wiki_train_nltk', 'df_wiki_train_aoa', 'df_wiki_train_crb', 'df_wiki_train_w2v']\n",
      "118\n",
      "(416768, 118)\n",
      "(416768,)\n",
      "Cross-validating: Random Forerst\n",
      "0.7457218395613874\n",
      "\n",
      "['df_wiki_train_stats', 'df_wiki_train_nltk', 'df_wiki_train_aoa', 'df_wiki_train_crb', 'df_wiki_train_w2v']\n",
      "120\n",
      "(416768, 120)\n",
      "(416768,)\n",
      "Cross-validating: Random Forerst\n",
      "0.7516675985864287\n",
      "\n",
      "['df_wiki_train_stats', 'df_wiki_train_rs', 'df_wiki_train_aoa', 'df_wiki_train_crb', 'df_wiki_train_w2v']\n",
      "115\n",
      "(416768, 115)\n",
      "(416768,)\n",
      "Cross-validating: Random Forerst\n",
      "0.7460049713026768\n",
      "\n",
      "['df_wiki_train_stats', 'df_wiki_train_rs', 'df_wiki_train_nltk', 'df_wiki_train_crb', 'df_wiki_train_w2v']\n",
      "111\n",
      "(416768, 111)\n",
      "(416768,)\n",
      "Cross-validating: Random Forerst\n",
      "0.7411821454803826\n",
      "\n",
      "['df_wiki_train_stats', 'df_wiki_train_rs', 'df_wiki_train_nltk', 'df_wiki_train_aoa', 'df_wiki_train_w2v']\n",
      "143\n",
      "(416768, 143)\n",
      "(416768,)\n",
      "Cross-validating: Random Forerst\n",
      "0.7489610488490591\n",
      "\n",
      "['df_wiki_train_stats', 'df_wiki_train_rs', 'df_wiki_train_nltk', 'df_wiki_train_aoa', 'df_wiki_train_crb']\n",
      "148\n",
      "(416768, 148)\n",
      "(416768,)\n",
      "Cross-validating: Random Forerst\n",
      "0.7469911250089447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through the list and exclude one dataframe each time\n",
    "for i in range(len(dataset_df_list)):\n",
    "    df_train = pd.DataFrame()\n",
    "    # Exclude the i-th dataset\n",
    "    excluded_dataset_list = dataset_df_list[:i] + dataset_df_list[i+1:]\n",
    "    dataframes_list.append(list_of_dataset_list[i])\n",
    "    print(list_of_dataset_list[i])\n",
    "\n",
    "    # Concatenate the remaining datasets along axis 1 (i.e., horizontally)\n",
    "    df_train = pd.concat(excluded_dataset_list, axis=1)\n",
    "\n",
    "    X_columns_train = df_train.columns.to_list()\n",
    "    X_columns_train = list(set(X_columns_train) - {\"label\", \"original_text\", \"cleaned_text\", \"stats_language_code\"})\n",
    "\n",
    "    X = df_train[X_columns_train].copy()\n",
    "    y = df_wiki_train_stats[\"label\"]\n",
    "\n",
    "    #ic(X_columns_train);\n",
    "    print(len(X_columns_train))\n",
    "    print(X.shape);\n",
    "    print(y.shape);\n",
    "\n",
    "    features_list.append(len(X_columns_train))\n",
    "    acc_list.append(calculate_acc(model_pipeline, X, y))\n",
    "\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_groups</th>\n",
       "      <th>features</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[df_wiki_train_stats, df_wiki_train_rs, df_wiki_train_nltk, df_wiki_train_aoa, df_wiki_train_crb, df_wiki_train_w2v]</td>\n",
       "      <td>151</td>\n",
       "      <td>0.748889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[df_wiki_train_rs, df_wiki_train_nltk, df_wiki_train_aoa, df_wiki_train_crb, df_wiki_train_w2v]</td>\n",
       "      <td>118</td>\n",
       "      <td>0.745722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[df_wiki_train_stats, df_wiki_train_nltk, df_wiki_train_aoa, df_wiki_train_crb, df_wiki_train_w2v]</td>\n",
       "      <td>120</td>\n",
       "      <td>0.751668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[df_wiki_train_stats, df_wiki_train_rs, df_wiki_train_aoa, df_wiki_train_crb, df_wiki_train_w2v]</td>\n",
       "      <td>115</td>\n",
       "      <td>0.746005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[df_wiki_train_stats, df_wiki_train_rs, df_wiki_train_nltk, df_wiki_train_crb, df_wiki_train_w2v]</td>\n",
       "      <td>111</td>\n",
       "      <td>0.741182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[df_wiki_train_stats, df_wiki_train_rs, df_wiki_train_nltk, df_wiki_train_aoa, df_wiki_train_w2v]</td>\n",
       "      <td>143</td>\n",
       "      <td>0.748961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[df_wiki_train_stats, df_wiki_train_rs, df_wiki_train_nltk, df_wiki_train_aoa, df_wiki_train_crb]</td>\n",
       "      <td>148</td>\n",
       "      <td>0.746991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                         feature_groups  \\\n",
       "0  [df_wiki_train_stats, df_wiki_train_rs, df_wiki_train_nltk, df_wiki_train_aoa, df_wiki_train_crb, df_wiki_train_w2v]   \n",
       "1                       [df_wiki_train_rs, df_wiki_train_nltk, df_wiki_train_aoa, df_wiki_train_crb, df_wiki_train_w2v]   \n",
       "2                    [df_wiki_train_stats, df_wiki_train_nltk, df_wiki_train_aoa, df_wiki_train_crb, df_wiki_train_w2v]   \n",
       "3                      [df_wiki_train_stats, df_wiki_train_rs, df_wiki_train_aoa, df_wiki_train_crb, df_wiki_train_w2v]   \n",
       "4                     [df_wiki_train_stats, df_wiki_train_rs, df_wiki_train_nltk, df_wiki_train_crb, df_wiki_train_w2v]   \n",
       "5                     [df_wiki_train_stats, df_wiki_train_rs, df_wiki_train_nltk, df_wiki_train_aoa, df_wiki_train_w2v]   \n",
       "6                     [df_wiki_train_stats, df_wiki_train_rs, df_wiki_train_nltk, df_wiki_train_aoa, df_wiki_train_crb]   \n",
       "\n",
       "   features  accuracy  \n",
       "0       151  0.748889  \n",
       "1       118  0.745722  \n",
       "2       120  0.751668  \n",
       "3       115  0.746005  \n",
       "4       111  0.741182  \n",
       "5       143  0.748961  \n",
       "6       148  0.746991  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame({\n",
    "    'feature_groups': dataframes_list,\n",
    "    'features': features_list,\n",
    "    'accuracy': acc_list\n",
    "})\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.21 minutes\n"
     ]
    }
   ],
   "source": [
    "t_end = time.time()\n",
    "calculate_duration(t_start, t_end);\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not FASTRUN:\n",
    "    df_results.to_csv(ROOT_PATH+PATH_DATA_REP+f'{today}_feature_ablation-table_{notebook_no}.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ti9wgudgBzw9"
   },
   "source": [
    "# Watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "f7PuaC1JBzw-",
    "outputId": "aafeadff-3431-44e5-fa8f-d94281a641d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2023-02-21T00:57:08.446144+01:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.9.0\n",
      "IPython version      : 8.9.0\n",
      "\n",
      "Compiler    : Clang 11.0.0 \n",
      "OS          : Darwin\n",
      "Release     : 22.3.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 10\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "SU12PVZ2BzxA",
    "outputId": "35145233-ba98-423f-ca77-95011e8cd3af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seaborn   : 0.12.2\n",
      "pandas    : 1.5.3\n",
      "matplotlib: 3.6.3\n",
      "numpy     : 1.23.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BdlIIXzYnOiW"
   },
   "source": [
    "-----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook 04.04_feature_ablation_GC.ipynb to html\n",
      "[NbConvertApp] Writing 632773 bytes to ../reports/html/2023-02-21_04.04_feature_ablation_GC.html\n"
     ]
    }
   ],
   "source": [
    "output_file = f'{ROOT_PATH}{PATH_DATA_HTML}{today}_04.03_feature_selection_feature_ablation.html'\n",
    "!jupyter nbconvert --to html \"04.03_feature_selection_feature_ablation.ipynb\" --output {output_file}"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "deepnote": {},
  "deepnote_app_layout": "article",
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "9a9c04096ce744f096ec4c3e58773e56",
  "deepnote_persisted_session": {
   "createdAt": "2023-01-25T20:01:30.909Z"
  },
  "kernelspec": {
   "display_name": "siads696",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "e06bb46ff2b522e8ed41cde06a3284743bf4ee3b709766dafa5d4f926bdfb013"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
