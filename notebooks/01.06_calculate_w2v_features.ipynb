{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "97e9abac2ee54b5c8ba21bcf1a802d4d",
    "deepnote_cell_type": "markdown",
    "id": "wd0JhzeqBzw0"
   },
   "source": [
    "- The objective of this **01.06** notebook is to \n",
    "  - calculate the average word2vec value per sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20001,
     "status": "ok",
     "timestamp": 1675456213726,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "om7csB9O0YKP",
    "outputId": "c2d66d80-df23-4407-89a7-71f0b7fb4514"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a Goolge Drive Environment.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "except:\n",
    "    print(\"Not a Goolge Drive Environment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "executionInfo": {
     "elapsed": 378,
     "status": "ok",
     "timestamp": 1675456214098,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "xxhnY2O80XCs"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "t_start = time.time()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ac47ba3d7145431da2416323b62232e5",
    "deepnote_cell_type": "markdown",
    "id": "uZms1pauBzw0"
   },
   "source": [
    "# Setup Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d8b22853ac04404bb216a71d63002736",
    "deepnote_cell_type": "markdown",
    "id": "FSazCCmDbqKg"
   },
   "source": [
    "## Install Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "cell_id": "6633271503fe42df89ba3569caef9907",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "executionInfo": {
     "elapsed": 82577,
     "status": "ok",
     "timestamp": 1675456296672,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "execution_millis": 5522,
    "execution_start": 1674663419536,
    "id": "1Vo8zBrWbqKg",
    "outputId": "b8e4eec4-3e0a-4497-dbb5-9b26bc031888",
    "source_hash": "aef1fc25"
   },
   "outputs": [],
   "source": [
    "#!pip install watermark\n",
    "#!pip install gensim\n",
    "#!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12562,
     "status": "ok",
     "timestamp": 1675456309223,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "o6mVxLcK10-y",
    "outputId": "5f17010d-1572-435c-f5a0-9097cdacb91d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/busera/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('popular')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4a55b1f05bb74b87998290bb84cbfb92",
    "deepnote_cell_type": "markdown",
    "id": "hHwYAoFSBzw1"
   },
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "cell_id": "1dc7a166b2134cdaba740b2b70550d40",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "executionInfo": {
     "elapsed": 1241,
     "status": "ok",
     "timestamp": 1675456310453,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "execution_millis": 928,
    "execution_start": 1674663425059,
    "id": "nbk1jSYhBzw2",
    "source_hash": "9bc7a04c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n"
     ]
    }
   ],
   "source": [
    "# Base libraries\n",
    "import os\n",
    "import re\n",
    "import platform\n",
    "\n",
    "# Scientific libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(8,4)})\n",
    "sns.set(font_scale=0.8)\n",
    "\n",
    "# Helper libraries\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from watermark import watermark\n",
    "import gc # garbage collection to optimize memory usage, use gc.collect()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Pandas options\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "# Load magic commands\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "executionInfo": {
     "elapsed": 559,
     "status": "ok",
     "timestamp": 1675456311002,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "okbUwoEe0XCy"
   },
   "outputs": [],
   "source": [
    "# Specific libraries\n",
    "import gensim\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import gensim.downloader as gensim_api\n",
    "import fasttext as ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "649c1930a7cc466c8aed4f0f70e3c7c6",
    "deepnote_cell_type": "markdown",
    "id": "C46IJ3IeBzw5"
   },
   "source": [
    "## Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1675456311002,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "irtratQx0XCy"
   },
   "outputs": [],
   "source": [
    "# None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8y1w2f4d0XCz"
   },
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1675456311003,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "aWxsXJDE0XCz"
   },
   "outputs": [],
   "source": [
    "import http.client, urllib\n",
    "\n",
    "def send_push(message):\n",
    "\t\"\"\"Send push notifications to pushover service.\"\"\"\n",
    "\tconn = http.client.HTTPSConnection(\"api.pushover.net:443\")\n",
    "\tconn.request(\"POST\", \"/1/messages.json\",\n",
    "\turllib.parse.urlencode({\n",
    "\t\t\"token\": \"ahs1q4mwpnxe3645zeaqzas69whq7a\",  # ML Notifications Channel\n",
    "\t\t\"user\": \"u5vr1qkc9ghudg2ehuug153okeiz1d\",\n",
    "\t\t\"message\": message,\n",
    "\t}), { \"Content-type\": \"application/x-www-form-urlencoded\" })\n",
    "\n",
    "\tconn.getresponse()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f8befebe274f40b595ba4704155feb1e",
    "deepnote_cell_type": "markdown",
    "id": "6YBbHzbqBzw8"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "executionInfo": {
     "elapsed": 4616,
     "status": "ok",
     "timestamp": 1675456318152,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "PB_8grcN0wtX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a Goolge Drive Environment. Loading local files.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Location for \"shared with\" people\n",
    "    # create a shortcut of the shared folder in your Google Drive root folder\n",
    "    PATH_DATA = \"/content/drive/MyDrive/SIADS696/Environment/data/\"\n",
    "    PATH_DATA_RAW = \"/content/drive/MyDrive/SIADS696/Environment/data/raw/\"\n",
    "    PATH_DATA_INT = \"/content/drive/MyDrive/SIADS696/Environment/data/interim/\"\n",
    "    PATH_DATA_PRO = \"/content/drive/MyDrive/SIADS696/Environment/data/processed/\"\n",
    "    PATH_DATA_MOD = \"/content/drive/MyDrive/SIADS696/Environment/models/\"\n",
    "\n",
    "    df_wiki_train = pd.read_parquet(PATH_DATA_INT + \"train_features_clean_stats.parquet.gzip\")\n",
    "    df_wiki_test = pd.read_parquet(PATH_DATA_INT + \"test_features_clean_stats.parquet.gzip\")\n",
    "\n",
    "except:\n",
    "    print(\"Not a Goolge Drive Environment. Loading local files.\")\n",
    "    PATH_DATA = \"../data/\"\n",
    "    PATH_DATA_RAW = \"../data/raw/\"\n",
    "    PATH_DATA_INT = \"../data/interim/\"\n",
    "    PATH_DATA_PRO = \"../data/interim/\"\n",
    "    PATH_DATA_MOD = \"../models/\"\n",
    "    \n",
    "    df_wiki_train = pd.read_parquet(PATH_DATA_INT + \"train_features_clean_stats.parquet.gzip\")\n",
    "    df_wiki_test = pd.read_parquet(PATH_DATA_INT + \"test_features_clean_stats.parquet.gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "cell_id": "c54204539e2241059353846387137cc0",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1675456318152,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "execution_millis": 32,
    "execution_start": 1674663426948,
    "id": "Uxya1mIG0XC0",
    "outputId": "8a0cd54c-250b-4056-b072-6c3e37eaad4e",
    "source_hash": "5ac8384"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(416768, 37)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(119092, 38)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wiki_train.shape\n",
    "df_wiki_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "41cf505bfda54eae8ca783855354abe9",
    "deepnote_cell_type": "markdown",
    "id": "CL9zJrfHr_iA"
   },
   "source": [
    "# 4.0 Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CMkjKQrZ0XC1"
   },
   "source": [
    "**Tips on Creating Features**\n",
    "- Linear models learn sums and differences naturally, but can't learn anything more complex.\n",
    "- Ratios seem to be difficult for most models to learn. Ratio combinations often lead to some easy performance gains.\n",
    "- Linear models and neural nets generally do better with normalized features. Neural nets especially need features scaled to values not too far from 0. Tree-based models (like random forests and XGBoost) can sometimes benefit from normalization, but usually much less so.\n",
    "- Tree models can learn to approximate almost any combination of features, but when a combination is especially important they can still benefit from having it explicitly created, especially when data is limited.\n",
    "- Counts are especially helpful for tree models, since these models don't have a natural way of aggregating information across many features at once.\n",
    "[Source](https://www.kaggle.com/code/ryanholbrook/creating-features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9a2cccf4521d4d15a8d3391af62c5661",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [],
    "id": "3zRyygHV0XC1",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "### Calculate avg word2vec Features (w2v_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_H9Ankx50XC1"
   },
   "source": [
    "## Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 628280,
     "status": "ok",
     "timestamp": 1675456946421,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "zi9aiNnn0XC1",
    "outputId": "b1b65f78-e42b-4bea-b142-e4783368c75a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.5 s, sys: 1.78 s, total: 24.3 s\n",
      "Wall time: 27.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Gensim\n",
    "wv = gensim_api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1675456946422,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "FZKIXJRh0XC1"
   },
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "def create_lemma(text_list):\n",
    "    text_list = [lemmatizer.lemmatize(word) for word in text_list]\n",
    "    return text_list\n",
    "\n",
    "def avg_word2vec(sentence_list, model):\n",
    "    result = np.mean(np.mean([model.wv[word] for word in sentence_list if word in model.wv.index_to_key], axis=0))\n",
    "    return result.round(5)\n",
    "\n",
    "\n",
    "def ft_avg_word2vec(sentence_list, model):\n",
    "    result= np.mean(np.mean([model.get_word_vector(word) for word in sentence_list]))\n",
    "    return result.round(5)\n",
    "\n",
    "\n",
    "def ft_avg_sent2vec(sentence_list, model):\n",
    "    result = np.mean(model.get_sentence_vector(sentence_list))\n",
    "    return result.round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 142924,
     "status": "ok",
     "timestamp": 1675457089336,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "3t7Kk3Jw0XC2",
    "outputId": "72b9c093-a993-43e4-df1d-0d7140b94091"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 416768/416768 [00:40<00:00, 10341.34it/s]\n",
      "100%|██████████| 119092/119092 [00:07<00:00, 16073.63it/s]\n",
      "100%|██████████| 416768/416768 [00:16<00:00, 25337.00it/s]\n",
      "100%|██████████| 119092/119092 [00:04<00:00, 27210.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.6 s, sys: 8.91 s, total: 1min 1s\n",
      "Wall time: 1min 9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_wiki_train['tokenized'] = df_wiki_train['cleaned_text'].progress_apply(nltk.word_tokenize)\n",
    "df_wiki_test['tokenized'] = df_wiki_test['cleaned_text'].progress_apply(nltk.word_tokenize)\n",
    "df_wiki_train['tokenized_lemma'] = df_wiki_train['tokenized'].progress_apply(create_lemma)\n",
    "df_wiki_test['tokenized_lemma'] = df_wiki_test['tokenized'].progress_apply(create_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1675457089337,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "sJ7nGoMu0XC2"
   },
   "outputs": [],
   "source": [
    "# Only use English tokenized lemma\n",
    "df_wiki_train_en = df_wiki_train[df_wiki_train['stats_language_code'] == 'en'].copy()\n",
    "sentences_wiki_train_en = df_wiki_train_en['tokenized_lemma'].to_list()\n",
    "\n",
    "df_wiki_test_en = df_wiki_test[df_wiki_test['stats_language_code'] == 'en'].copy()\n",
    "sentences_wiki_test_en = df_wiki_test_en['tokenized_lemma'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wiki_train_nonen = df_wiki_train[df_wiki_train['stats_language_code'] != 'en'].copy()\n",
    "df_wiki_test_nonen = df_wiki_test[df_wiki_test['stats_language_code'] != 'en'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 81611,
     "status": "ok",
     "timestamp": 1675457170942,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "T7U0cVNu0XC2",
    "outputId": "3dc92e4d-c606-4896-e416-8ce6035b0bbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 9s, sys: 1.66 s, total: 1min 11s\n",
      "Wall time: 25.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Lets train Word2vec model\n",
    "word2vec_model_wiki_train_en = gensim.models.Word2Vec(sentences_wiki_train_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23818,
     "status": "ok",
     "timestamp": 1675457194754,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "g7jXYO7_0XC2",
    "outputId": "4ebc2da9-353d-4249-9676-365936d6ba0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.8 s, sys: 239 ms, total: 19.1 s\n",
      "Wall time: 6.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Lets train Word2vec model\n",
    "word2vec_model_wiki_test_en = gensim.models.Word2Vec(sentences_wiki_test_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 409238/409238 [07:50<00:00, 869.91it/s] \n",
      "100%|██████████| 117060/117060 [01:17<00:00, 1501.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 56s, sys: 8.5 s, total: 9min 5s\n",
      "Wall time: 9min 8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_wiki_train_en['w2v_gen_avg_word2vec_mean'] = df_wiki_train_en['tokenized_lemma'].progress_apply(\n",
    "    lambda x: avg_word2vec(x, word2vec_model_wiki_train_en))\n",
    "\n",
    "df_wiki_test_en['w2v_gen_avg_word2vec_mean'] = df_wiki_test_en['tokenized_lemma'].progress_apply(\n",
    "    lambda x: avg_word2vec(x, word2vec_model_wiki_test_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wiki_train_nonen['w2v_gen_avg_word2vec_mean'] = -1\n",
    "df_wiki_test_nonen['w2v_gen_avg_word2vec_mean'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #df_wiki_train['tokenized_lemma'] = df_wiki_train['tokenized_lemma'].fillna(-1)\n",
    "# df_wiki_train['w2v_gen_avg_word2vec_mean']= np.where(\n",
    "#                             df_wiki_train['stats_language_code'] == 'en',\n",
    "#                             df_wiki_train['tokenized_lemma'].apply(lambda x: avg_word2vec(x, word2vec_model_wiki_train),\n",
    "#                             -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #df_wiki_test['tokenized_lemma'] = df_wiki_test['tokenized_lemma'].fillna(-1)\n",
    "# df_wiki_test['w2v_gen_avg_word2vec_mean']= np.where(\n",
    "#                         df_wiki_test['stats_language_code'] == 'en',\n",
    "#                         df_wiki_test['tokenized_lemma'].apply(lambda x: avg_word2vec(x, word2vec_model_wiki_test),\n",
    "#                         -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lledBesh0XC3"
   },
   "source": [
    "## Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1675457195145,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "G-4Aq8_y0XC3"
   },
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "#fasttext.util.download_model('en', if_exists='ignore')  # English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1675457195145,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "5vufDKg00XC3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# https://fasttext.cc/docs/en/crawl-vectors.html\n",
    "ft_model = fasttext.load_model('../models/fasttext_cc.en.300.bin')\n",
    "#ft_model = fasttext.load_model(PATH_MOD+fn_ft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 409238/409238 [01:20<00:00, 5087.80it/s] \n",
      "100%|██████████| 117060/117060 [00:08<00:00, 13186.95it/s]\n"
     ]
    }
   ],
   "source": [
    "df_wiki_train_en['w2v_ft_sen2vec_mean'] = df_wiki_train_en['cleaned_text'].progress_apply(\n",
    "    lambda x: ft_avg_sent2vec(x, ft_model))\n",
    "df_wiki_test_en['w2v_ft_sen2vec_mean'] = df_wiki_test_en['cleaned_text'].progress_apply(\n",
    "    lambda x: ft_avg_sent2vec(x, ft_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 409238/409238 [02:18<00:00, 2964.08it/s]\n",
      "100%|██████████| 117060/117060 [00:35<00:00, 3333.69it/s]\n"
     ]
    }
   ],
   "source": [
    "df_wiki_train_en['w2v_ft_word2vec_mean'] = df_wiki_train_en['cleaned_text'].progress_apply(\n",
    "    lambda x: ft_avg_word2vec(x, ft_model))\n",
    "df_wiki_test_en['w2v_ft_word2vec_mean'] = df_wiki_test_en['cleaned_text'].progress_apply(\n",
    "    lambda x: ft_avg_word2vec(x, ft_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wiki_train_nonen['w2v_ft_sen2vec_mean'] = -1\n",
    "df_wiki_test_nonen['w2v_ft_sen2vec_mean'] = -1\n",
    "\n",
    "df_wiki_train_nonen['w2v_ft_word2vec_mean'] = -1\n",
    "df_wiki_test_nonen['w2v_ft_word2vec_mean'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1675457195146,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "ltcQdL7U0XC3"
   },
   "outputs": [],
   "source": [
    "# df_wiki_train['w2v_ft_sen2vec_mean'] = df_wiki_train['cleaned_text'].progress_apply(\n",
    "#     lambda x: ft_avg_sent2vec(x, ft_model))\n",
    "# df_wiki_test['w2v_ft_sen2vec_mean'] = df_wiki_test['cleaned_text'].progress_apply(\n",
    "#     lambda x: ft_avg_sent2vec(x, ft_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df_wiki_train['w2v_ft_sen2vec_mean'] = np.where(\n",
    "#                                     df_wiki_train['stats_language_code'] == 'en',\n",
    "#                                     df_wiki_train['cleaned_text'].apply(lambda x: ft_avg_sent2vec(x, ft_model),\n",
    "#                                     -1))\n",
    "\n",
    "# df_wiki_test['w2v_ft_sen2vec_mean'] = np.where(\n",
    "#                                     df_wiki_test['stats_language_code'] == 'en',\n",
    "#                                     df_wiki_test['cleaned_text'].apply(lambda x: ft_avg_sent2vec(x, ft_model),\n",
    "#                                     -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1675457195146,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "cFtnEZTQ0XC3"
   },
   "outputs": [],
   "source": [
    "# df_wiki_train['w2v_ft_word2vec_mean'] = df_wiki_train['cleaned_text'].progress_apply(\n",
    "#     lambda x: ft_avg_word2vec(x, ft_model))\n",
    "# df_wiki_test['w2v_ft_word2vec_mean'] = df_wiki_test['cleaned_text'].progress_apply(\n",
    "#     lambda x: ft_avg_word2vec(x, ft_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df_wiki_train['w2v_ft_word2vec_mean'] = np.where(\n",
    "#                                         df_wiki_train['stats_language_code'] == 'en',\n",
    "#                                         df_wiki_train['cleaned_text'].apply(lambda x: ft_avg_word2vec(x, ft_model),\n",
    "#                                         -1))\n",
    "\n",
    "# df_wiki_test['w2v_ft_word2vec_mean'] = np.where(\n",
    "#                                         df_wiki_test['stats_language_code'] == 'en',\n",
    "#                                         df_wiki_test['cleaned_text'].apply(lambda x: ft_avg_word2vec(x, ft_model),\n",
    "#                                         -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUEO_egu0XC3"
   },
   "source": [
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wiki_train = pd.DataFrame()\n",
    "df_wiki_train = pd.concat([df_wiki_train_en, df_wiki_train_nonen], axis =0).sort_index()\n",
    "\n",
    "df_wiki_test = pd.DataFrame()\n",
    "df_wiki_test = pd.concat([df_wiki_test_en, df_wiki_test_nonen], axis =0).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1675457195146,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "wuIgnqmf0XC4"
   },
   "outputs": [],
   "source": [
    "df_wiki_train.fillna(-1, inplace=True)\n",
    "df_wiki_test.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(416768, 42)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(119092, 43)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wiki_train.shape\n",
    "df_wiki_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>label</th>\n",
       "      <th>stats_lrb_count</th>\n",
       "      <th>stats_rrb_count</th>\n",
       "      <th>stats_comma_count</th>\n",
       "      <th>stats_equalsign_count</th>\n",
       "      <th>stats_char_count</th>\n",
       "      <th>stats_image_description</th>\n",
       "      <th>stats_frac_description</th>\n",
       "      <th>stats_file_description</th>\n",
       "      <th>stats_formula_description</th>\n",
       "      <th>stats_language_code</th>\n",
       "      <th>stats_avg_char_per_word</th>\n",
       "      <th>stats_word_count</th>\n",
       "      <th>stats_letter_count</th>\n",
       "      <th>stats_long_word_count</th>\n",
       "      <th>stats_syllable_count</th>\n",
       "      <th>stats_polysyllab_count</th>\n",
       "      <th>stats_monosyllab_count</th>\n",
       "      <th>stats_reading_time</th>\n",
       "      <th>stats_avg_letter_per_word</th>\n",
       "      <th>stats_sentence_length</th>\n",
       "      <th>stats_syllable_avg</th>\n",
       "      <th>stats_mini_word_count</th>\n",
       "      <th>stats_long_numbers_count</th>\n",
       "      <th>stats_lexical_diversity</th>\n",
       "      <th>stats_frac_word_comma</th>\n",
       "      <th>stats_frac_mini_word</th>\n",
       "      <th>stats_frac_long_word</th>\n",
       "      <th>stats_frac_monosyllable</th>\n",
       "      <th>stats_frac_polysyllable</th>\n",
       "      <th>stats_max_chars_word</th>\n",
       "      <th>stats_avg_chars_word</th>\n",
       "      <th>stats_max_syllables_word</th>\n",
       "      <th>stats_avg_syllables_word</th>\n",
       "      <th>stats_language_no</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>tokenized_lemma</th>\n",
       "      <th>w2v_gen_avg_word2vec_mean</th>\n",
       "      <th>w2v_ft_sen2vec_mean</th>\n",
       "      <th>w2v_ft_word2vec_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There is manuscript evidence that Austen continued to work on these pieces as late as the period 1809 â '' 11 , and that her niece and nephew , Anna and James Edward Austen , made further additions as late as 1814 .</td>\n",
       "      <td>there is manuscript evidence that austen continued to work on these pieces as late as the period 1809 11 and that her niece and nephew anna and james edward austen made further additions as late as 1814</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>4.5</td>\n",
       "      <td>37</td>\n",
       "      <td>166</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>18</td>\n",
       "      <td>[there, is, manuscript, evidence, that, austen, continued, to, work, on, these, pieces, as, late, as, the, period, 1809, 11, and, that, her, niece, and, nephew, anna, and, james, edward, austen, made, further, additions, as, late, as, 1814]</td>\n",
       "      <td>[there, is, manuscript, evidence, that, austen, continued, to, work, on, these, piece, a, late, a, the, period, 1809, 11, and, that, her, niece, and, nephew, anna, and, james, edward, austen, made, further, addition, a, late, a, 1814]</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In a remarkable comparative analysis , Mandaean scholar Säve-Söderberg demonstrated that Mani 's Psalms of Thomas were closely related to Mandaean texts .</td>\n",
       "      <td>in a remarkable comparative analysis mandaean scholar saeve soederberg demonstrated that mani psalms of thomas were closely related to mandaean texts</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>6.1</td>\n",
       "      <td>21</td>\n",
       "      <td>129</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1.9</td>\n",
       "      <td>6.1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>12</td>\n",
       "      <td>6.1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>18</td>\n",
       "      <td>[in, a, remarkable, comparative, analysis, mandaean, scholar, saeve, soederberg, demonstrated, that, mani, psalms, of, thomas, were, closely, related, to, mandaean, texts]</td>\n",
       "      <td>[in, a, remarkable, comparative, analysis, mandaean, scholar, saeve, soederberg, demonstrated, that, mani, psalm, of, thomas, were, closely, related, to, mandaean, text]</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Before Persephone was released to Hermes , who had been sent to retrieve her , Hades tricked her into eating pomegranate seeds , -LRB- six or three according to the telling -RRB- which forced her to return to the underworld for a period each year .</td>\n",
       "      <td>before persephone was released to hermes who had been sent to retrieve her hades tricked her into eating pomegranate seeds six or three according to the telling which forced her to return to the underworld for a period each year</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>4.7</td>\n",
       "      <td>40</td>\n",
       "      <td>189</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>18</td>\n",
       "      <td>[before, persephone, was, released, to, hermes, who, had, been, sent, to, retrieve, her, hades, tricked, her, into, eating, pomegranate, seeds, six, or, three, according, to, the, telling, which, forced, her, to, return, to, the, underworld, for, a, period, each, year]</td>\n",
       "      <td>[before, persephone, wa, released, to, hermes, who, had, been, sent, to, retrieve, her, hades, tricked, her, into, eating, pomegranate, seed, six, or, three, according, to, the, telling, which, forced, her, to, return, to, the, underworld, for, a, period, each, year]</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cogeneration plants are commonly found in district heating systems of cities , hospitals , prisons , oil refineries , paper mills , wastewater treatment plants , thermal enhanced oil recovery wells and industrial plants with large heating needs .</td>\n",
       "      <td>cogeneration plants are commonly found in district heating systems of cities hospitals prisons oil refineries paper mills wastewater treatment plants thermal enhanced oil recovery wells and industrial plants with large heating needs</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>6.3</td>\n",
       "      <td>32</td>\n",
       "      <td>201</td>\n",
       "      <td>15</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>12</td>\n",
       "      <td>6.3</td>\n",
       "      <td>5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>18</td>\n",
       "      <td>[cogeneration, plants, are, commonly, found, in, district, heating, systems, of, cities, hospitals, prisons, oil, refineries, paper, mills, wastewater, treatment, plants, thermal, enhanced, oil, recovery, wells, and, industrial, plants, with, large, heating, needs]</td>\n",
       "      <td>[cogeneration, plant, are, commonly, found, in, district, heating, system, of, city, hospital, prison, oil, refinery, paper, mill, wastewater, treatment, plant, thermal, enhanced, oil, recovery, well, and, industrial, plant, with, large, heating, need]</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                              original_text  \\\n",
       "0                                   There is manuscript evidence that Austen continued to work on these pieces as late as the period 1809 â '' 11 , and that her niece and nephew , Anna and James Edward Austen , made further additions as late as 1814 .   \n",
       "1                                                                                                In a remarkable comparative analysis , Mandaean scholar Säve-Söderberg demonstrated that Mani 's Psalms of Thomas were closely related to Mandaean texts .   \n",
       "2  Before Persephone was released to Hermes , who had been sent to retrieve her , Hades tricked her into eating pomegranate seeds , -LRB- six or three according to the telling -RRB- which forced her to return to the underworld for a period each year .   \n",
       "3    Cogeneration plants are commonly found in district heating systems of cities , hospitals , prisons , oil refineries , paper mills , wastewater treatment plants , thermal enhanced oil recovery wells and industrial plants with large heating needs .   \n",
       "\n",
       "                                                                                                                                                                                                                               cleaned_text  \\\n",
       "0                                there is manuscript evidence that austen continued to work on these pieces as late as the period 1809 11 and that her niece and nephew anna and james edward austen made further additions as late as 1814   \n",
       "1                                                                                     in a remarkable comparative analysis mandaean scholar saeve soederberg demonstrated that mani psalms of thomas were closely related to mandaean texts   \n",
       "2      before persephone was released to hermes who had been sent to retrieve her hades tricked her into eating pomegranate seeds six or three according to the telling which forced her to return to the underworld for a period each year   \n",
       "3  cogeneration plants are commonly found in district heating systems of cities hospitals prisons oil refineries paper mills wastewater treatment plants thermal enhanced oil recovery wells and industrial plants with large heating needs   \n",
       "\n",
       "   label  stats_lrb_count  stats_rrb_count  stats_comma_count  \\\n",
       "0      1                0                0                  3   \n",
       "1      1                0                0                  1   \n",
       "2      1                1                1                  3   \n",
       "3      1                0                0                  6   \n",
       "\n",
       "   stats_equalsign_count  stats_char_count  stats_image_description  \\\n",
       "0                      0               173                        0   \n",
       "1                      0               132                        0   \n",
       "2                      0               203                        0   \n",
       "3                      0               208                        0   \n",
       "\n",
       "   stats_frac_description  stats_file_description  stats_formula_description  \\\n",
       "0                       0                       0                          0   \n",
       "1                       0                       0                          0   \n",
       "2                       0                       0                          0   \n",
       "3                       0                       0                          0   \n",
       "\n",
       "  stats_language_code  stats_avg_char_per_word  stats_word_count  \\\n",
       "0                  en                      4.5                37   \n",
       "1                  en                      6.1                21   \n",
       "2                  en                      4.7                40   \n",
       "3                  en                      6.3                32   \n",
       "\n",
       "   stats_letter_count  stats_long_word_count  stats_syllable_count  \\\n",
       "0                 166                      5                    50   \n",
       "1                 129                     10                    34   \n",
       "2                 189                      8                    52   \n",
       "3                 201                     15                    56   \n",
       "\n",
       "   stats_polysyllab_count  stats_monosyllab_count  stats_reading_time  \\\n",
       "0                       3                      27                 2.4   \n",
       "1                       3                      12                 1.9   \n",
       "2                       2                      30                 2.8   \n",
       "3                       5                      16                 3.0   \n",
       "\n",
       "   stats_avg_letter_per_word  stats_sentence_length  stats_syllable_avg  \\\n",
       "0                        4.5                   37.0                 1.4   \n",
       "1                        6.1                   21.0                 1.6   \n",
       "2                        4.7                   40.0                 1.3   \n",
       "3                        6.3                   32.0                 1.8   \n",
       "\n",
       "   stats_mini_word_count  stats_long_numbers_count  stats_lexical_diversity  \\\n",
       "0                     12                         0                      0.8   \n",
       "1                      4                         0                      1.0   \n",
       "2                     17                         0                      0.8   \n",
       "3                      6                         0                      0.9   \n",
       "\n",
       "   stats_frac_word_comma  stats_frac_mini_word  stats_frac_long_word  \\\n",
       "0                    0.1                   0.3                   0.1   \n",
       "1                    0.0                   0.2                   0.5   \n",
       "2                    0.1                   0.4                   0.2   \n",
       "3                    0.2                   0.2                   0.5   \n",
       "\n",
       "   stats_frac_monosyllable  stats_frac_polysyllable  stats_max_chars_word  \\\n",
       "0                      0.7                      0.1                    10   \n",
       "1                      0.6                      0.1                    12   \n",
       "2                      0.8                      0.0                    11   \n",
       "3                      0.5                      0.2                    12   \n",
       "\n",
       "   stats_avg_chars_word  stats_max_syllables_word  stats_avg_syllables_word  \\\n",
       "0                   4.5                         3                       1.4   \n",
       "1                   6.1                         4                       1.6   \n",
       "2                   4.7                         3                       1.3   \n",
       "3                   6.3                         5                       1.8   \n",
       "\n",
       "   stats_language_no  \\\n",
       "0                 18   \n",
       "1                 18   \n",
       "2                 18   \n",
       "3                 18   \n",
       "\n",
       "                                                                                                                                                                                                                                                                       tokenized  \\\n",
       "0                               [there, is, manuscript, evidence, that, austen, continued, to, work, on, these, pieces, as, late, as, the, period, 1809, 11, and, that, her, niece, and, nephew, anna, and, james, edward, austen, made, further, additions, as, late, as, 1814]   \n",
       "1                                                                                                    [in, a, remarkable, comparative, analysis, mandaean, scholar, saeve, soederberg, demonstrated, that, mani, psalms, of, thomas, were, closely, related, to, mandaean, texts]   \n",
       "2  [before, persephone, was, released, to, hermes, who, had, been, sent, to, retrieve, her, hades, tricked, her, into, eating, pomegranate, seeds, six, or, three, according, to, the, telling, which, forced, her, to, return, to, the, underworld, for, a, period, each, year]   \n",
       "3      [cogeneration, plants, are, commonly, found, in, district, heating, systems, of, cities, hospitals, prisons, oil, refineries, paper, mills, wastewater, treatment, plants, thermal, enhanced, oil, recovery, wells, and, industrial, plants, with, large, heating, needs]   \n",
       "\n",
       "                                                                                                                                                                                                                                                               tokenized_lemma  \\\n",
       "0                                   [there, is, manuscript, evidence, that, austen, continued, to, work, on, these, piece, a, late, a, the, period, 1809, 11, and, that, her, niece, and, nephew, anna, and, james, edward, austen, made, further, addition, a, late, a, 1814]   \n",
       "1                                                                                                    [in, a, remarkable, comparative, analysis, mandaean, scholar, saeve, soederberg, demonstrated, that, mani, psalm, of, thomas, were, closely, related, to, mandaean, text]   \n",
       "2  [before, persephone, wa, released, to, hermes, who, had, been, sent, to, retrieve, her, hades, tricked, her, into, eating, pomegranate, seed, six, or, three, according, to, the, telling, which, forced, her, to, return, to, the, underworld, for, a, period, each, year]   \n",
       "3                 [cogeneration, plant, are, commonly, found, in, district, heating, system, of, city, hospital, prison, oil, refinery, paper, mill, wastewater, treatment, plant, thermal, enhanced, oil, recovery, well, and, industrial, plant, with, large, heating, need]   \n",
       "\n",
       "   w2v_gen_avg_word2vec_mean  w2v_ft_sen2vec_mean  w2v_ft_word2vec_mean  \n",
       "0                     -0.096               -0.000                 0.005  \n",
       "1                     -0.053               -0.001                 0.003  \n",
       "2                     -0.114               -0.001                 0.003  \n",
       "3                      0.100               -0.002                 0.003  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wiki_train.head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "edfe7b5a16aa42b1a0325a87598851aa",
    "deepnote_cell_type": "markdown",
    "id": "xjBxesfBr_iG"
   },
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1675457195147,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "eR3Swt2R1SSV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w2v_ft_sen2vec_mean', 'w2v_ft_word2vec_mean', 'w2v_gen_avg_word2vec_mean']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = df_wiki_train.columns.to_list()\n",
    "feature_columns = sorted([x for x in columns if x.startswith(\"w2v_\")])\n",
    "\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "cell_id": "018f5ac3e61d4f40ab1427890ed4a012",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1675457195147,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "WA96B6840XC4",
    "source_hash": "d764c53e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Export AoA features\n",
    "df_export = df_wiki_train[feature_columns]\n",
    "df_export.to_csv(PATH_DATA_INT + \"train_features_w2v.csv\", index=False)\n",
    "df_export.to_parquet(PATH_DATA_INT + \"train_features_w2v.parquet.gzip\", compression='gzip')\n",
    "\n",
    "df_export = df_wiki_test[feature_columns]\n",
    "df_export.to_csv(PATH_DATA_INT + \"test_features_w2v.csv\", index=False)\n",
    "df_export.to_parquet(PATH_DATA_INT + \"test_features_w2v.parquet.gzip\", compression='gzip')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a462da01ed494c7e8277477f4dbd7b9b",
    "deepnote_cell_type": "markdown",
    "id": "ti9wgudgBzw9"
   },
   "source": [
    "# Watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "cell_id": "e269fc38ee844d49891383e27ce68fb2",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1675457195147,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "execution_millis": 31,
    "execution_start": 1674582478187,
    "id": "f7PuaC1JBzw-",
    "source_hash": "ee060237"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2023-02-13T17:49:39.645487+01:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.9.15\n",
      "IPython version      : 8.8.0\n",
      "\n",
      "Compiler    : Clang 14.0.6 \n",
      "OS          : Darwin\n",
      "Release     : 22.2.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "cell_id": "42f5e2903d7941a79bf882cea20bc6fb",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "executionInfo": {
     "elapsed": 19,
     "status": "aborted",
     "timestamp": 1675457195148,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "execution_millis": 36,
    "execution_start": 1674582478222,
    "id": "SU12PVZ2BzxA",
    "source_hash": "82959e25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re      : 2.2.1\n",
      "gensim  : 4.3.0\n",
      "nltk    : 3.8.1\n",
      "platform: 1.0.8\n",
      "fasttext: 0.9.2\n",
      "numpy   : 1.23.5\n",
      "seaborn : 0.12.2\n",
      "pandas  : 1.5.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "aborted",
     "timestamp": 1675457195148,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "f7WXghHX0XC4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.13 minutes\n"
     ]
    }
   ],
   "source": [
    "t_end = time.time()\n",
    "total_runtime = t_end-t_start\n",
    "total_runtime_min = round((total_runtime/60),2)\n",
    "print(str(total_runtime_min)+\" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "aborted",
     "timestamp": 1675457195149,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "HFvaeePN0XC5"
   },
   "outputs": [],
   "source": [
    "send_push(f\"Calculate word2vec features finished in: {total_runtime_min} min.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Fkm1Nh1PjkGk",
    "FSazCCmDbqKg"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "946229b10e114987a52132227b87775b",
  "deepnote_persisted_session": {
   "createdAt": "2023-01-25T16:45:43.444Z"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
