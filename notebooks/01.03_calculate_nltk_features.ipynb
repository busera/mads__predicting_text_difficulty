{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v1.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this notebook is to \n",
    "- calcualte the nltk features (nltk_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54239,
     "status": "ok",
     "timestamp": 1675437068088,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "5xdFMQ08mFP3",
    "outputId": "a36ef1cc-9780-4826-c9a2-8c5bc3bd3e47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a Goolge Drive Environment.\n"
     ]
    }
   ],
   "source": [
    "## Check for Google Drive Connectivity\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    google_env = True\n",
    "except:\n",
    "    print(\"Not a Goolge Drive Environment.\")\n",
    "    google_env = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1675437068088,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "O-lYgqF1k89D"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "t_start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wd0JhzeqBzw0"
   },
   "source": [
    "- The objective of this **01.03** notebook is to \n",
    "  - calculate the nltk pos tag features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "uZms1pauBzw0"
   },
   "source": [
    "# Setup Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSazCCmDbqKg"
   },
   "source": [
    "## Install Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10656,
     "status": "ok",
     "timestamp": 1675437078737,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "1Vo8zBrWbqKg",
    "outputId": "c7ff1466-3a62-4a3a-c936-204543247590"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: watermark in /Users/busera/Miniconda/miniconda3/envs/siads696/lib/python3.9/site-packages (2.3.1)\n",
      "Requirement already satisfied: ipython in /Users/busera/Miniconda/miniconda3/envs/siads696/lib/python3.9/site-packages (from watermark) (8.9.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/busera/Miniconda/miniconda3/envs/siads696/lib/python3.9/site-packages (from ipython->watermark) (4.8.0)\n",
      "Requirement already satisfied: backcall in /Users/busera/Miniconda/miniconda3/envs/siads696/lib/python3.9/site-packages (from ipython->watermark) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /Users/busera/Miniconda/miniconda3/envs/siads696/lib/python3.9/site-packages (from ipython->watermark) (0.7.5)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/busera/Miniconda/miniconda3/envs/siads696/lib/python3.9/site-packages (from ipython->watermark) (0.1.6)\n",
      "Requirement already satisfied: decorator in /Users/busera/Miniconda/miniconda3/envs/siads696/lib/python3.9/site-packages (from ipython->watermark) (5.1.1)\n",
      "Requirement already satisfied: appnope in /Users/busera/Miniconda/miniconda3/envs/siads696/lib/python3.9/site-packages (from ipython->watermark) (0.1.3)\n",
      "Requirement already satisfied: traitlets>=5 in /Users/busera/Miniconda/miniconda3/envs/siads696/lib/python3.9/site-packages (from ipython->watermark) (5.9.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/busera/Miniconda/miniconda3/envs/siads696/lib/python3.9/site-packages (from ipython->watermark) (0.18.2)\n",
      "Requirement already satisfied: stack-data in /Users/busera/Miniconda/miniconda3/envs/siads696/lib/python3.9/site-packages (from ipython->watermark) (0.6.2)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/busera/Miniconda/miniconda3/envs/siads696/lib/python3.9/site-packages (from ipython->watermark) (2.14.0)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.30 in /Users/busera/Miniconda/miniconda3/envs/siads696/lib/python3.9/site-packages (from ipython->watermark) (3.0.36)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/busera/Miniconda/miniconda3/envs/siads696/lib/python3.9/site-packages (from jedi>=0.16->ipython->watermark) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/busera/Miniconda/miniconda3/envs/siads696/lib/python3.9/site-packages (from pexpect>4.3->ipython->watermark) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/busera/Miniconda/miniconda3/envs/siads696/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.30->ipython->watermark) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/busera/Miniconda/miniconda3/envs/siads696/lib/python3.9/site-packages (from stack-data->ipython->watermark) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/busera/Miniconda/miniconda3/envs/siads696/lib/python3.9/site-packages (from stack-data->ipython->watermark) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /Users/busera/Miniconda/miniconda3/envs/siads696/lib/python3.9/site-packages (from stack-data->ipython->watermark) (0.2.2)\n",
      "Requirement already satisfied: six in /Users/busera/Miniconda/miniconda3/envs/siads696/lib/python3.9/site-packages (from asttokens>=2.1.0->stack-data->ipython->watermark) (1.16.0)\n",
      "Requirement already satisfied: nltk in /Users/busera/Miniconda/miniconda3/envs/siads696/lib/python3.9/site-packages (3.8.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/busera/Miniconda/miniconda3/envs/siads696/lib/python3.9/site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: click in /Users/busera/Miniconda/miniconda3/envs/siads696/lib/python3.9/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: tqdm in /Users/busera/Miniconda/miniconda3/envs/siads696/lib/python3.9/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: joblib in /Users/busera/Miniconda/miniconda3/envs/siads696/lib/python3.9/site-packages (from nltk) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install watermark\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14090,
     "status": "ok",
     "timestamp": 1675437092820,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "2LshMx8ClBVT",
    "outputId": "bd4d7240-49d4-4eae-b239-da54712482f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/busera/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/busera/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('popular')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHwYAoFSBzw1"
   },
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1181,
     "status": "ok",
     "timestamp": 1675437093990,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "nbk1jSYhBzw2"
   },
   "outputs": [],
   "source": [
    "# Base libraries\n",
    "import os\n",
    "import re\n",
    "from datetime import date\n",
    "\n",
    "# Scientific libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(8,4)})\n",
    "sns.set(font_scale=0.8)\n",
    "\n",
    "# Helper libraries\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from watermark import watermark\n",
    "import gc # garbage collection to optimize memory usage, use gc.collect()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Pandas options\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "# Load magic commands\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C46IJ3IeBzw5"
   },
   "source": [
    "## Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1675437093991,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "rVPFKtMUBzw6"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "cpu_count = os.cpu_count()\n",
    "cpu_count = cpu_count-2  # to keep machine responsive when fitting the models\n",
    "notebook_no = \"01.03\"\n",
    "today = date.today()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "2Pnbv9Wtk89P"
   },
   "source": [
    "## Global Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1675437093991,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "80_Ay7ZRk89P"
   },
   "outputs": [],
   "source": [
    "import http.client\n",
    "import urllib\n",
    "\n",
    "\n",
    "def send_push(message):\n",
    "    \"\"\"Send push notifications to pushover service.\"\"\"\n",
    "    try:\n",
    "        conn = http.client.HTTPSConnection(\"api.pushover.net:443\")\n",
    "        conn.request(\"POST\", \"/1/messages.json\",\n",
    "                     urllib.parse.urlencode({\n",
    "                         \"token\": \"ahs1q4mwpnxe3645zeaqzas69whq7a\",  # ML Notifications Channel\n",
    "                         \"user\": \"u5vr1qkc9ghudg2ehuug153okeiz1d\",\n",
    "                         \"message\": message,\n",
    "                     }), {\"Content-type\": \"application/x-www-form-urlencoded\"})\n",
    "\n",
    "        conn.getresponse()\n",
    "\n",
    "    except:\n",
    "        print(\"There was a communication issue (pushover).\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "6YBbHzbqBzw8"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6867,
     "status": "ok",
     "timestamp": 1675437103005,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "JFZQQ-x_k89Q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a Google Drive Environment. Loading local files.\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "if google_env:\n",
    "    # Location for \"shared with\" people\n",
    "    # create a shortcut of the shared folder in your Google Drive root folder\n",
    "    ROOT_PATH = \"/content/drive/MyDrive/SIADS696/Environment/\"\n",
    "else:\n",
    "    ROOT_PATH = \"../\"\n",
    "    print(\"Not a Google Drive Environment. Loading local files.\")\n",
    "\n",
    "PATH_DATA = \"data/\"\n",
    "PATH_DATA_RAW = \"data/raw/\"\n",
    "PATH_DATA_INT = \"data/interim/\"\n",
    "PATH_DATA_PRO = \"data/processed/\"\n",
    "PATH_DATA_MOD = \"models/\"\n",
    "PATH_DATA_REP = \"reports/\"\n",
    "PATH_DATA_FIG = \"reports/figures/\"\n",
    "PATH_DATA_HTML = \"reports/html/\"\n",
    "\n",
    "df_wiki_train = pd.read_parquet(ROOT_PATH + PATH_DATA_INT + \"train_features_clean_stats.parquet.gzip\")\n",
    "df_wiki_test = pd.read_parquet(ROOT_PATH + PATH_DATA_INT + \"test_features_clean_stats.parquet.gzip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1675437103006,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "ZRXrUWPak89R",
    "outputId": "d30025a1-521e-4b0d-dcc4-d0d22823515a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(416768, 37)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(119092, 38)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wiki_train.shape\n",
    "df_wiki_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CL9zJrfHr_iA"
   },
   "source": [
    "# 4.0 Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsmVPu-Kk89S"
   },
   "source": [
    "**Tips on Creating Features**\n",
    "- Linear models learn sums and differences naturally, but can't learn anything more complex.\n",
    "- Ratios seem to be difficult for most models to learn. Ratio combinations often lead to some easy performance gains.\n",
    "- Linear models and neural nets generally do better with normalized features. Neural nets especially need features scaled to values not too far from 0. Tree-based models (like random forests and XGBoost) can sometimes benefit from normalization, but usually much less so.\n",
    "- Tree models can learn to approximate almost any combination of features, but when a combination is especially important they can still benefit from having it explicitly created, especially when data is limited.\n",
    "- Counts are especially helpful for tree models, since these models don't have a natural way of aggregating information across many features at once.\n",
    "[Source](https://www.kaggle.com/code/ryanholbrook/creating-features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqR_gJ2Uk89T"
   },
   "source": [
    "### Count verbs, nouns, and other parts of speech (nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GrJa2Iaok89T"
   },
   "source": [
    "https://practicaldatascience.co.uk/data-science/how-to-use-nltk-for-pos-tagging-in-pandas\n",
    "https://stackoverflow.com/questions/48930871/creating-a-function-to-count-the-number-of-pos-in-a-pandas-instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1675437103006,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "AF9UctoUk89U"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1675437103007,
     "user": {
      "displayName": "V A",
      "userId": "07747803009706112600"
     },
     "user_tz": -60
    },
    "id": "f8480ofRk89U"
   },
   "outputs": [],
   "source": [
    "def count_nltk_pos_tags(text, nltk_pos_tags):\n",
    "    a = pd.Series(text)\n",
    "    result = a.map(lambda x: 1 if x[1]== nltk_pos_tags else 0).sum()\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def count_stopwords(word_tokens):\n",
    "    nltk_stopwords = (stopwords.words('english'))\n",
    "    stopwords_list = [w for w in word_tokens if w in nltk_stopwords]\n",
    "\n",
    "    return len(stopwords_list)\n",
    "\n",
    "\n",
    "def nltk_pos_tags_count(df):\n",
    "    nltk_pos_tags = ['CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ',\n",
    "                     'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNS', 'NNP',\n",
    "                     'NNPS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', \n",
    "                     'RBR', 'RBS', 'RP', 'TO', 'UH', 'VB', 'VBD', \n",
    "                     'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', \n",
    "                     'WP$', 'WRB']\n",
    "\n",
    "    print(\"Creating tokens.\")\n",
    "    df['tokenized'] = df['cleaned_text'].progress_apply(nltk.word_tokenize)\n",
    "    \n",
    "    print(\"Counting stopwords.\")\n",
    "    df['nltk_stopwords_count'] = df['tokenized'].progress_apply(count_stopwords)\n",
    "    \n",
    "    print(\"Assigning nltk_pos_tags.\")\n",
    "    df['tagged'] = df['tokenized'].progress_apply(nltk.pos_tag)\n",
    "\n",
    "    print(\"Counting nltk_pos_tags.\")\n",
    "    for tag in tqdm(nltk_pos_tags):\n",
    "        df[\"nltk_pos_\"+tag] = df['tagged'].apply(lambda x: count_nltk_pos_tags(x, tag))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "zlBjMRVZk89V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tokens.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 416768/416768 [00:21<00:00, 19037.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting stopwords.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 416768/416768 [00:26<00:00, 15744.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning nltk_pos_tags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 416768/416768 [02:43<00:00, 2541.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting nltk_pos_tags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [13:44<00:00, 23.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16min 58s, sys: 17.1 s, total: 17min 15s\n",
      "Wall time: 17min 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# MBPM1: 16.30 min\n",
    "# Deepnote (Plus): 53 min?\n",
    "# Windows ML (32 GB): 38 min !!\n",
    "# Google Colab (Pro): \n",
    "\n",
    "df_wiki_train = nltk_pos_tags_count(df_wiki_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "VF0OtQYwk89V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tokens.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119092/119092 [00:06<00:00, 19130.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting stopwords.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119092/119092 [00:07<00:00, 15276.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning nltk_pos_tags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119092/119092 [00:48<00:00, 2479.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting nltk_pos_tags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [03:53<00:00,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 50s, sys: 4.98 s, total: 4min 55s\n",
      "Wall time: 4min 55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# MBPM1: 4.52 min\n",
    "# Deepnote (Plus): 15 min?\n",
    "# Google Colab (Pro): \n",
    "\n",
    "df_wiki_test = nltk_pos_tags_count(df_wiki_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_3vFOu3-k89V"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>original_text</th>\n",
       "      <td>There is manuscript evidence that Austen continued to work on these pieces as late as the period 1809 â '' 11 , and that her niece and nephew , Anna and James Edward Austen , made further additions as late as 1814 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleaned_text</th>\n",
       "      <td>there is manuscript evidence that austen continued to work on these pieces as late as the period 1809 11 and that her niece and nephew anna and james edward austen made further additions as late as 1814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_lrb_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_rrb_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_comma_count</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_equalsign_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_char_count</th>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_image_description</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_frac_description</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_file_description</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_formula_description</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_language_code</th>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_avg_char_per_word</th>\n",
       "      <td>4.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_word_count</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_letter_count</th>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_long_word_count</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_syllable_count</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_polysyllab_count</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_monosyllab_count</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_reading_time</th>\n",
       "      <td>2.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_avg_letter_per_word</th>\n",
       "      <td>4.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_sentence_length</th>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_syllable_avg</th>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_mini_word_count</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_long_numbers_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_lexical_diversity</th>\n",
       "      <td>0.783784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_frac_word_comma</th>\n",
       "      <td>0.081081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_frac_mini_word</th>\n",
       "      <td>0.324324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_frac_long_word</th>\n",
       "      <td>0.135135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_frac_monosyllable</th>\n",
       "      <td>0.72973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_frac_polysyllable</th>\n",
       "      <td>0.081081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_max_chars_word</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_avg_chars_word</th>\n",
       "      <td>4.486486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_max_syllables_word</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_avg_syllables_word</th>\n",
       "      <td>1.351351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_language_no</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokenized</th>\n",
       "      <td>[there, is, manuscript, evidence, that, austen, continued, to, work, on, these, pieces, as, late, as, the, period, 1809, 11, and, that, her, niece, and, nephew, anna, and, james, edward, austen, made, further, additions, as, late, as, 1814]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_stopwords_count</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tagged</th>\n",
       "      <td>[(there, EX), (is, VBZ), (manuscript, JJ), (evidence, NN), (that, WDT), (austen, VBZ), (continued, VBN), (to, TO), (work, VB), (on, IN), (these, DT), (pieces, NNS), (as, RB), (late, RB), (as, IN), (the, DT), (period, NN), (1809, CD), (11, CD), (and, CC), (that, IN), (her, PRP$), (niece, NN), (and, CC), (nephew, JJ), (anna, NN), (and, CC), (james, NNS), (edward, RB), (austen, VB), (made, VBN), (further, JJ), (additions, NNS), (as, RB), (late, RB), (as, IN), (1814, CD)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_CC</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_CD</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_DT</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_EX</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_FW</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_IN</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_JJ</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_JJR</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_JJS</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_LS</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_MD</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_NN</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_NNS</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_NNP</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_NNPS</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_PDT</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_POS</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_PRP</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_PRP$</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_RB</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_RBR</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_RBS</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_RP</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_TO</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_UH</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_VB</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_VBD</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_VBG</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_VBN</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_VBP</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_VBZ</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_WDT</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_WP</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_WP$</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_WRB</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  0\n",
       "original_text                                                                                                                                                                                                                                                                               There is manuscript evidence that Austen continued to work on these pieces as late as the period 1809 â '' 11 , and that her niece and nephew , Anna and James Edward Austen , made further additions as late as 1814 .\n",
       "cleaned_text                                                                                                                                                                                                                                                                                             there is manuscript evidence that austen continued to work on these pieces as late as the period 1809 11 and that her niece and nephew anna and james edward austen made further additions as late as 1814\n",
       "label                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             1\n",
       "stats_lrb_count                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   0\n",
       "stats_rrb_count                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   0\n",
       "stats_comma_count                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 3\n",
       "stats_equalsign_count                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             0\n",
       "stats_char_count                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                173\n",
       "stats_image_description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           0\n",
       "stats_frac_description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            0\n",
       "stats_file_description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            0\n",
       "stats_formula_description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         0\n",
       "stats_language_code                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              en\n",
       "stats_avg_char_per_word                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        4.49\n",
       "stats_word_count                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 37\n",
       "stats_letter_count                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              166\n",
       "stats_long_word_count                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             5\n",
       "stats_syllable_count                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             50\n",
       "stats_polysyllab_count                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            3\n",
       "stats_monosyllab_count                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           27\n",
       "stats_reading_time                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             2.44\n",
       "stats_avg_letter_per_word                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      4.49\n",
       "stats_sentence_length                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          37.0\n",
       "stats_syllable_avg                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              1.4\n",
       "stats_mini_word_count                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            12\n",
       "stats_long_numbers_count                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          0\n",
       "stats_lexical_diversity                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    0.783784\n",
       "stats_frac_word_comma                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      0.081081\n",
       "stats_frac_mini_word                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       0.324324\n",
       "stats_frac_long_word                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       0.135135\n",
       "stats_frac_monosyllable                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     0.72973\n",
       "stats_frac_polysyllable                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    0.081081\n",
       "stats_max_chars_word                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             10\n",
       "stats_avg_chars_word                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       4.486486\n",
       "stats_max_syllables_word                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          3\n",
       "stats_avg_syllables_word                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1.351351\n",
       "stats_language_no                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                18\n",
       "tokenized                                                                                                                                                                                                                                                          [there, is, manuscript, evidence, that, austen, continued, to, work, on, these, pieces, as, late, as, the, period, 1809, 11, and, that, her, niece, and, nephew, anna, and, james, edward, austen, made, further, additions, as, late, as, 1814]\n",
       "nltk_stopwords_count                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             17\n",
       "tagged                     [(there, EX), (is, VBZ), (manuscript, JJ), (evidence, NN), (that, WDT), (austen, VBZ), (continued, VBN), (to, TO), (work, VB), (on, IN), (these, DT), (pieces, NNS), (as, RB), (late, RB), (as, IN), (the, DT), (period, NN), (1809, CD), (11, CD), (and, CC), (that, IN), (her, PRP$), (niece, NN), (and, CC), (nephew, JJ), (anna, NN), (and, CC), (james, NNS), (edward, RB), (austen, VB), (made, VBN), (further, JJ), (additions, NNS), (as, RB), (late, RB), (as, IN), (1814, CD)]\n",
       "nltk_pos_CC                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       3\n",
       "nltk_pos_CD                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       3\n",
       "nltk_pos_DT                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       2\n",
       "nltk_pos_EX                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       1\n",
       "nltk_pos_FW                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       0\n",
       "nltk_pos_IN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       4\n",
       "nltk_pos_JJ                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       3\n",
       "nltk_pos_JJR                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      0\n",
       "nltk_pos_JJS                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      0\n",
       "nltk_pos_LS                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       0\n",
       "nltk_pos_MD                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       0\n",
       "nltk_pos_NN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       4\n",
       "nltk_pos_NNS                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      3\n",
       "nltk_pos_NNP                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      0\n",
       "nltk_pos_NNPS                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     0\n",
       "nltk_pos_PDT                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      0\n",
       "nltk_pos_POS                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      0\n",
       "nltk_pos_PRP                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      0\n",
       "nltk_pos_PRP$                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     1\n",
       "nltk_pos_RB                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       5\n",
       "nltk_pos_RBR                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      0\n",
       "nltk_pos_RBS                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      0\n",
       "nltk_pos_RP                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       0\n",
       "nltk_pos_TO                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       1\n",
       "nltk_pos_UH                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       0\n",
       "nltk_pos_VB                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       2\n",
       "nltk_pos_VBD                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      0\n",
       "nltk_pos_VBG                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      0\n",
       "nltk_pos_VBN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      2\n",
       "nltk_pos_VBP                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      0\n",
       "nltk_pos_VBZ                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      2\n",
       "nltk_pos_WDT                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      1\n",
       "nltk_pos_WP                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       0\n",
       "nltk_pos_WP$                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      0\n",
       "nltk_pos_WRB                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wiki_train.head(1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "SuHMDjZsk89W"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleaned_text</th>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_text</th>\n",
       "      <td>-2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_lrb_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_rrb_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_comma_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_equalsign_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_char_count</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_image_description</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_frac_description</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_file_description</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_formula_description</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_language_code</th>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_avg_char_per_word</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_word_count</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_letter_count</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_long_word_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_syllable_count</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_polysyllab_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_monosyllab_count</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_reading_time</th>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_avg_letter_per_word</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_sentence_length</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_syllable_avg</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_mini_word_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_long_numbers_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_lexical_diversity</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_frac_word_comma</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_frac_mini_word</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_frac_long_word</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_frac_monosyllable</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_frac_polysyllable</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_max_chars_word</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_avg_chars_word</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_max_syllables_word</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_avg_syllables_word</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_language_no</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokenized</th>\n",
       "      <td>[2011]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_stopwords_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tagged</th>\n",
       "      <td>[(2011, CD)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_CC</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_CD</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_DT</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_EX</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_FW</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_IN</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_JJ</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_JJR</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_JJS</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_LS</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_MD</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_NN</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_NNS</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_NNP</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_NNPS</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_PDT</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_POS</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_PRP</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_PRP$</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_RB</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_RBR</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_RBS</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_RP</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_TO</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_UH</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_VB</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_VBD</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_VBG</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_VBN</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_VBP</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_VBZ</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_WDT</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_WP</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_WP$</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk_pos_WRB</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      0\n",
       "id                                    0\n",
       "cleaned_text                       2011\n",
       "original_text                     -2011\n",
       "label                              -1.0\n",
       "stats_lrb_count                       0\n",
       "stats_rrb_count                       0\n",
       "stats_comma_count                     0\n",
       "stats_equalsign_count                 0\n",
       "stats_char_count                      5\n",
       "stats_image_description               0\n",
       "stats_frac_description                0\n",
       "stats_file_description                0\n",
       "stats_formula_description             0\n",
       "stats_language_code                  fr\n",
       "stats_avg_char_per_word             4.0\n",
       "stats_word_count                      1\n",
       "stats_letter_count                    4\n",
       "stats_long_word_count                 0\n",
       "stats_syllable_count                  1\n",
       "stats_polysyllab_count                0\n",
       "stats_monosyllab_count                1\n",
       "stats_reading_time                 0.06\n",
       "stats_avg_letter_per_word           4.0\n",
       "stats_sentence_length               1.0\n",
       "stats_syllable_avg                  1.0\n",
       "stats_mini_word_count                 0\n",
       "stats_long_numbers_count              0\n",
       "stats_lexical_diversity             1.0\n",
       "stats_frac_word_comma               0.0\n",
       "stats_frac_mini_word                0.0\n",
       "stats_frac_long_word                0.0\n",
       "stats_frac_monosyllable             1.0\n",
       "stats_frac_polysyllable             0.0\n",
       "stats_max_chars_word                  4\n",
       "stats_avg_chars_word                4.0\n",
       "stats_max_syllables_word              1\n",
       "stats_avg_syllables_word            1.0\n",
       "stats_language_no                    19\n",
       "tokenized                        [2011]\n",
       "nltk_stopwords_count                  0\n",
       "tagged                     [(2011, CD)]\n",
       "nltk_pos_CC                           0\n",
       "nltk_pos_CD                           1\n",
       "nltk_pos_DT                           0\n",
       "nltk_pos_EX                           0\n",
       "nltk_pos_FW                           0\n",
       "nltk_pos_IN                           0\n",
       "nltk_pos_JJ                           0\n",
       "nltk_pos_JJR                          0\n",
       "nltk_pos_JJS                          0\n",
       "nltk_pos_LS                           0\n",
       "nltk_pos_MD                           0\n",
       "nltk_pos_NN                           0\n",
       "nltk_pos_NNS                          0\n",
       "nltk_pos_NNP                          0\n",
       "nltk_pos_NNPS                         0\n",
       "nltk_pos_PDT                          0\n",
       "nltk_pos_POS                          0\n",
       "nltk_pos_PRP                          0\n",
       "nltk_pos_PRP$                         0\n",
       "nltk_pos_RB                           0\n",
       "nltk_pos_RBR                          0\n",
       "nltk_pos_RBS                          0\n",
       "nltk_pos_RP                           0\n",
       "nltk_pos_TO                           0\n",
       "nltk_pos_UH                           0\n",
       "nltk_pos_VB                           0\n",
       "nltk_pos_VBD                          0\n",
       "nltk_pos_VBG                          0\n",
       "nltk_pos_VBN                          0\n",
       "nltk_pos_VBP                          0\n",
       "nltk_pos_VBZ                          0\n",
       "nltk_pos_WDT                          0\n",
       "nltk_pos_WP                           0\n",
       "nltk_pos_WP$                          0\n",
       "nltk_pos_WRB                          0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wiki_test.head(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjBxesfBr_iG"
   },
   "source": [
    "# 5.0 Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2fYZhEy2lvUl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "['nltk_pos_CC', 'nltk_pos_CD', 'nltk_pos_DT', 'nltk_pos_EX', 'nltk_pos_FW', 'nltk_pos_IN', 'nltk_pos_JJ', 'nltk_pos_JJR', 'nltk_pos_JJS', 'nltk_pos_LS', 'nltk_pos_MD', 'nltk_pos_NN', 'nltk_pos_NNP', 'nltk_pos_NNPS', 'nltk_pos_NNS', 'nltk_pos_PDT', 'nltk_pos_POS', 'nltk_pos_PRP', 'nltk_pos_PRP$', 'nltk_pos_RB', 'nltk_pos_RBR', 'nltk_pos_RBS', 'nltk_pos_RP', 'nltk_pos_TO', 'nltk_pos_UH', 'nltk_pos_VB', 'nltk_pos_VBD', 'nltk_pos_VBG', 'nltk_pos_VBN', 'nltk_pos_VBP', 'nltk_pos_VBZ', 'nltk_pos_WDT', 'nltk_pos_WP', 'nltk_pos_WP$', 'nltk_pos_WRB', 'nltk_stopwords_count']\n"
     ]
    }
   ],
   "source": [
    "columns = df_wiki_train.columns.to_list()\n",
    "feature_columns = sorted([x for x in columns if x.startswith(\"nltk_\")])\n",
    "\n",
    "print(len(feature_columns))\n",
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "KH-FZATjk89W"
   },
   "outputs": [],
   "source": [
    "# Export NLTK features\n",
    "df_export = df_wiki_train[feature_columns]\n",
    "#df_export.to_csv(ROOT_PATH+PATH_DATA_INT+\"train_features_nltk.csv\", index=False)\n",
    "df_export.to_parquet(ROOT_PATH+PATH_DATA_INT+\"train_features_nltk.parquet.gzip\", compression='gzip')\n",
    "\n",
    "df_export = df_wiki_test[feature_columns]\n",
    "#df_export.to_csv(ROOT_PATH+PATH_DATA_INT+\"test_features_nltk.csv\", index=False)\n",
    "df_export.to_parquet(ROOT_PATH+PATH_DATA_INT+\"test_features_nltk.parquet.gzip\", compression='gzip')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ti9wgudgBzw9"
   },
   "source": [
    "# 6.0 Watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "f7PuaC1JBzw-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2023-02-26T17:52:13.517981+01:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.9.0\n",
      "IPython version      : 8.9.0\n",
      "\n",
      "Compiler    : Clang 11.0.0 \n",
      "OS          : Darwin\n",
      "Release     : 22.3.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 10\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "SU12PVZ2BzxA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas : 1.5.3\n",
      "re     : 2.2.1\n",
      "nltk   : 3.8.1\n",
      "seaborn: 0.12.2\n",
      "numpy  : 1.23.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ysuvc-Juk89X"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.32 minutes\n"
     ]
    }
   ],
   "source": [
    "t_end = time.time()\n",
    "total_runtime = t_end-t_start\n",
    "total_runtime_min = round((total_runtime/60),2)\n",
    "print(str(total_runtime_min)+\" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "m1d2HkQfk89Y"
   },
   "outputs": [],
   "source": [
    "send_push(f\"01.03 Feature Engineering: Calculate nltk features finished in: {total_runtime_min} min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'today' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m output_file \u001B[39m=\u001B[39m \u001B[39mf\u001B[39m\u001B[39m'\u001B[39m\u001B[39m{\u001B[39;00mROOT_PATH\u001B[39m}\u001B[39;00m\u001B[39m{\u001B[39;00mPATH_DATA_HTML\u001B[39m}\u001B[39;00m\u001B[39m{\u001B[39;00mtoday\u001B[39m}\u001B[39;00m\u001B[39m_01.03_calculate_nltk_features_GC.html\u001B[39m\u001B[39m'\u001B[39m\n\u001B[1;32m      2\u001B[0m get_ipython()\u001B[39m.\u001B[39msystem(\u001B[39m'\u001B[39m\u001B[39mjupyter nbconvert --to html \u001B[39m\u001B[39m\"\u001B[39m\u001B[39m01.03_calculate_nltk_features_GC.ipynb\u001B[39m\u001B[39m\"\u001B[39m\u001B[39m --output \u001B[39m\u001B[39m{output_file}\u001B[39;00m\u001B[39m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'today' is not defined"
     ]
    }
   ],
   "source": [
    "output_file = f'{ROOT_PATH}{PATH_DATA_HTML}{today}_01.03_calculate_nltk_features.html'\n",
    "!jupyter nbconvert --to html \"01.03_calculate_nltk_features.ipynb\" --output {output_file}"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Fkm1Nh1PjkGk",
    "FSazCCmDbqKg"
   ],
   "name": "",
   "toc_visible": true,
   "version": ""
  },
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "946229b10e114987a52132227b87775b",
  "deepnote_persisted_session": {
   "createdAt": "2023-01-25T16:45:43.444Z"
  },
  "kernelspec": {
   "display_name": "siads696",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "e06bb46ff2b522e8ed41cde06a3284743bf4ee3b709766dafa5d4f926bdfb013"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
